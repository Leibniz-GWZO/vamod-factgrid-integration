================================================================================
ZUSAMMENFASSUNG - MACRO-AVERAGED METRICS
================================================================================
Modell                                        Precision    Recall       F1-Score    
--------------------------------------------------------------------------------
Reguläre Ausdrücke + manuell annotierte Listen 0.8086       0.8242       0.8088      
llama-3.3-70b-instruct                        0.7468       0.7839       0.7591      
gpt-4o                                        0.7932       0.8022       0.7953      
gpt-4.1                                       0.7489       0.7659       0.7532      

================================================================================
DETAILLIERTE ERGEBNISSE NACH ENTITY-TYP
================================================================================

--- Genannte Person ---
Modell                                        Precision    Recall       F1-Score    
--------------------------------------------------------------------------------
Reguläre Ausdrücke + manuell annotierte Listen 0.7607       0.7577       0.7460      
llama-3.3-70b-instruct                        0.8033       0.8367       0.8142      
gpt-4o                                        0.9243       0.9417       0.9298      
gpt-4.1                                       0.8014       0.8177       0.8065      

--- Empfängersitz ---
Modell                                        Precision    Recall       F1-Score    
--------------------------------------------------------------------------------
Reguläre Ausdrücke + manuell annotierte Listen 0.9000       0.9000       0.9000      
llama-3.3-70b-instruct                        0.6533       0.6600       0.6560      
gpt-4o                                        0.6733       0.6700       0.6693      
gpt-4.1                                       0.6333       0.6300       0.6293      

--- Objektort ---
Modell                                        Precision    Recall       F1-Score    
--------------------------------------------------------------------------------
Reguläre Ausdrücke + manuell annotierte Listen 0.7650       0.8150       0.7803      
llama-3.3-70b-instruct                        0.7837       0.8550       0.8071      
gpt-4o                                        0.7820       0.7950       0.7867      
gpt-4.1                                       0.8120       0.8500       0.8238      
